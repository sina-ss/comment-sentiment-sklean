{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading Data Without Preprocessing\n",
    "\n",
    "This is the simplest case where we just load the data without any modification to the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment sentiment\n",
      "0  Oh my god, it just doesn't get any worse than ...  negative\n",
      "1  If you're a layman interested in quantum theor...  negative\n",
      "2  It's amazing that this no talent actor Chapa g...  negative\n",
      "3  This must be one of the most overrated Spanish...  negative\n",
      "4  Some critics have compared Chop Shop with the ...  positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_data_without_preprocessing(file_path):\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# Usage\n",
    "file_path = 'dataset.csv'\n",
    "data = read_data_without_preprocessing(file_path)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic Text Preprocessing\n",
    "\n",
    "This method includes converting all letters to lower case, removing numbers, extra characters, and separating words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment sentiment\n",
      "0  oh my god it just doesn t get any worse than t...  negative\n",
      "1  if you re a layman interested in quantum theor...  negative\n",
      "2  it s amazing that this no talent actor chapa g...  negative\n",
      "3  this must be one of the most overrated spanish...  negative\n",
      "4  some critics have compared chop shop with the ...  positive\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def basic_text_preprocessing(data):\n",
    "    # Convert to lower case\n",
    "    data['comment'] = data['comment'].str.lower()\n",
    "    # Remove numbers and extra characters\n",
    "    data['comment'] = data['comment'].apply(lambda x: re.sub(r'\\d+', '', x))  # Remove digits\n",
    "    data['comment'] = data['comment'].apply(lambda x: re.sub(r'\\W+', ' ', x))  # Remove non-word characters\n",
    "    return data\n",
    "\n",
    "# Apply basic preprocessing\n",
    "data_basic_preprocessed = basic_text_preprocessing(data.copy())\n",
    "print(data_basic_preprocessed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. High-level Text Preprocessing\n",
    "\n",
    "This method includes all steps from the basic preprocessing plus removal of stopwords, stemming, and lemmatization. Additional methods from online references for text data preprocessing can be explored, such as using `nltk` for stopwords, stemming, and lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sina\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment sentiment\n",
      "0  oh god get wors alway love silli littl sci fi ...  negative\n",
      "1  layman interest quantum theori string theori r...  negative\n",
      "2  amaz talent actor chapa got well known star ap...  negative\n",
      "3  must one overr spanish film histori lack subtl...  negative\n",
      "4  critic compar chop shop theatric releas citi g...  positive\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def high_level_text_preprocessing(data):\n",
    "    # Initialize NLTK tools\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Remove stopwords, then stem and lemmatize the words\n",
    "    def preprocess_text(text):\n",
    "        words = nltk.word_tokenize(text)\n",
    "        filtered_words = [word for word in words if word not in stop_words]\n",
    "        stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in stemmed_words]\n",
    "        return ' '.join(lemmatized_words)\n",
    "    \n",
    "    data['comment'] = data['comment'].apply(preprocess_text)\n",
    "    return data\n",
    "\n",
    "# Apply high-level preprocessing\n",
    "data_high_level_preprocessed = high_level_text_preprocessing(data_basic_preprocessed.copy())\n",
    "print(data_high_level_preprocessed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Reason for Using These Methods\n",
    "\n",
    "Each preprocessing step is chosen based on common practices in NLP to improve the quality of input data for machine learning models:\n",
    "\n",
    "- **Lowercasing**: Helps in treating words like \"Hello\", \"HELLO\", and \"hello\" equally.\n",
    "- **Removing numbers and special characters**: Often, numbers and special characters do not carry useful information for sentiment analysis and can introduce noise into the data.\n",
    "- **Stopword removal**: Stopwords are common words that usually do not carry significant meaning and are removed to reduce the dataset size and improve processing time.\n",
    "- **Stemming and Lemmatization**: These processes reduce words to their root form, helping the model to understand that different forms of a word carry the same meaning.\n",
    "\n",
    "When implementing these preprocessing steps, it's important to remember that the effectiveness of each method can vary depending on the dataset and the specific task at hand. It's always a good idea to experiment with different preprocessing techniques and evaluate their impact on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the modeling quality using different text vectorization methods along with Logistic Regression and K-Nearest Neighbors (KNN) algorithms, we'll proceed through several steps:\n",
    "\n",
    "1. **High-level text preprocessing** of the dataset using the third method described previously.\n",
    "2. **Vectorization**: We'll use two vectorization methods: Bag of Words (BoW) and Word2Vec (although \"vec2Word\" was mentioned, I'll assume it's a reference to Word2Vec, a common word embedding technique).\n",
    "3. **Model Training and Hyperparameter Tuning**: For Logistic Regression and K-Nearest Neighbors (KNN), we'll adjust hyperparameters to find the best performing model.\n",
    "4. **Evaluation and Reporting**: We'll evaluate the models using appropriate metrics (like accuracy, precision, recall, and F1-score) and report the best settings.\n",
    "\n",
    "### Preparing the Environment\n",
    "\n",
    "First, ensure you have all necessary libraries installed and imported. We'll need `sklearn`, `gensim` for Word2Vec, `nltk` for text preprocessing, and `pandas` for data manipulation.\n",
    "\n",
    "### High-level Text Preprocessing\n",
    "\n",
    "We'll preprocess the dataset using the high-level text preprocessing method as described previously. This step is assumed to be completed, and the preprocessed dataset is ready for vectorization.\n",
    "\n",
    "### Vectorization Methods Implementation\n",
    "\n",
    "#### Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def vectorize_bow(texts):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    return X, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec\n",
    "\n",
    "For Word2Vec, we first need to train a model on our corpus or use a pre-trained model. Given the constraint of not using external data, we'll train a simple Word2Vec model on the preprocessed comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "def train_word2vec(sentences):\n",
    "    # Train a Word2Vec model\n",
    "    model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "    return model\n",
    "\n",
    "def vectorize_word2vec(model, sentences):\n",
    "    # Vectorize sentences using the average of word vectors\n",
    "    vectorized = []\n",
    "    for sentence in sentences:\n",
    "        vectors = [model.wv[word] for word in sentence if word in model.wv]\n",
    "        if vectors:\n",
    "            vectorized.append(np.mean(vectors, axis=0))\n",
    "        else:\n",
    "            vectorized.append(np.zeros(model.vector_size))\n",
    "    return np.array(vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Hyperparameter Tuning\n",
    "\n",
    "We'll split the dataset into training and test sets, then train and tune both Logistic Regression and KNN models for each vectorization method.\n",
    "\n",
    "#### Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming `data_high_level_preprocessed` is the dataset after high-level preprocessing\n",
    "X = data_high_level_preprocessed['comment']\n",
    "y = data_high_level_preprocessed['sentiment']\n",
    "\n",
    "# For BoW\n",
    "X_bow, vectorizer_bow = vectorize_bow(X)\n",
    "# Splitting for BoW\n",
    "X_train_bow, X_test_bow, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# For Word2Vec\n",
    "# Tokenize the sentences for Word2Vec\n",
    "sentences = [nltk.word_tokenize(comment) for comment in X]\n",
    "w2v_model = train_word2vec(sentences)\n",
    "X_w2v = vectorize_word2vec(w2v_model, sentences)\n",
    "# Splitting for Word2Vec\n",
    "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_w2v, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Hyperparameter Tuning\n",
    "\n",
    "Due to the complexity and the computational cost of hyperparameter tuning, I'll outline the approach for one model and vectorization method combination. You can replicate this approach for the other combinations.\n",
    "\n",
    "##### Logistic Regression with BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 0.1}\n",
      "Best score: 0.8846944444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Initialize the classifier\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit on the training data\n",
    "grid_search.fit(X_train_bow, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best score: {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-Nearest Neighbors with Bo\n",
    "\n",
    "You would follow a similar approach for KNN, adjusting parameters like `n_neighbors` and potentially the metric (e.g., Euclidean, Manhattan).\n",
    "\n",
    "### Evaluation and Reporting\n",
    "\n",
    "After training and tuning both models with both vectorization methods, evaluate each model on the test set to determine the best performing combination. Use metrics such as accuracy, precision, recall, and F1-score for a comprehensive evaluation.\n",
    "\n",
    "### Final Steps\n",
    "\n",
    "Repeat the process for each combination of models and vectorization techniques, adjusting hyperparameters as needed. Report the best models for Logistic Regression and KNN along with their hyperparameters and the vectorization method that led to the highest performance.\n",
    "\n",
    "Due to the execution and complexity involved in hyperparameter tuning and model training, you might want to run these experiments on your local machine or a cloud computing platform to manage computational resources effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [3, 5, 7, 9]}, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [3, 5, 7, 9]}, scoring=&#x27;accuracy&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [3, 5, 7, 9]}, scoring='accuracy')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle\n",
    "\n",
    "# Assuming data_high_level_preprocessed is loaded and contains 'comment' and 'sentiment' columns\n",
    "comments = data_high_level_preprocessed['comment']\n",
    "sentiments = data_high_level_preprocessed['sentiment']\n",
    "\n",
    "# Vectorize with BoW\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(comments)\n",
    "y = sentiments\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression with GridSearchCV\n",
    "param_grid_lr = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "grid_lr = GridSearchCV(LogisticRegression(max_iter=1000), param_grid_lr, cv=5, scoring='accuracy')\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "# KNN with GridSearchCV\n",
    "param_grid_knn = {'n_neighbors': [3, 5, 7, 9]}\n",
    "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5, scoring='accuracy')\n",
    "grid_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is Logistic Regression with a score of 0.8846944444444444.\n",
      "Best parameters: {'C': 0.1}\n",
      "Model saved to: mnt/data/pkl_LR.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory\n",
    "dir_path = 'mnt/data/'\n",
    "\n",
    "# Check if the directory exists, if not, create it\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "# Continue with your code\n",
    "if grid_lr.best_score_ > grid_knn.best_score_:\n",
    "    best_model = grid_lr.best_estimator_\n",
    "    best_score = grid_lr.best_score_\n",
    "    best_params = grid_lr.best_params_\n",
    "    model_type = \"Logistic Regression\"\n",
    "    save_path = os.path.join(dir_path, 'pkl_LR.pkl')\n",
    "else:\n",
    "    best_model = grid_knn.best_estimator_\n",
    "    best_score = grid_knn.best_score_\n",
    "    best_params = grid_knn.best_params_\n",
    "    model_type = \"KNN\"\n",
    "    save_path = os.path.join(dir_path, 'pkl_kNN.pkl')\n",
    "\n",
    "# Save the best model\n",
    "with open(save_path, 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(f\"The best model is {model_type} with a score of {best_score}.\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Model saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the points section\n",
    "For modeling with a Multilayer Perceptron (MLP) algorithm using scikit-learn's `MLPClassifier`, let's proceed through the necessary steps: preprocessing, vectorization, model training, and saving the best model. We'll explore different vectorization techniques and preprocessing methods to optimize performance.\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Given that there are no restrictions on data preprocessing, we will use high-level text preprocessing, including:\n",
    "- **Lowercasing**: Convert all text to lower case to ensure uniformity.\n",
    "- **Removing special characters and numbers**: Simplifies the text data.\n",
    "- **Tokenization**: Splits text into individual words or tokens.\n",
    "- **Removing stopwords**: Eliminates common words that may not contribute to the sentiment.\n",
    "- **Lemmatization**: Reduces words to their base or dictionary form.\n",
    "\n",
    "### Vectorization: TF-IDF\n",
    "\n",
    "In addition to Bag of Words (BoW) and Word2Vec, we'll use TF-IDF (Term Frequency-Inverse Document Frequency) for vectorization. TF-IDF highlights words that are more interesting, i.e., frequent in a document but not across documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Limit to 1000 features to manage model complexity\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(comments).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model Training\n",
    "\n",
    "For the MLPClassifier, we need to define several parameters:\n",
    "- **Number of layers and neurons**: A common starting point might be one hidden layer with a number of neurons between the size of the input layer and the output layer. However, for text data, more complex models might be necessary. We'll start with two hidden layers.\n",
    "- **Activation function**: `relu` (Rectified Linear Unit) is a common choice for hidden layers due to its efficiency and simplicity.\n",
    "- **Solver for weight optimization**: `adam` works well on large datasets with thousands of training samples.\n",
    "- **Regularization (`alpha`)**: Helps prevent overfitting by penalizing large weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.865\n",
      "Model saved as pkl_best.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_tfidf and y are already defined\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(512, 256), activation='relu', solver='adam', alpha=0.0001, max_iter=500, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions = mlp.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Assuming this model performs best, save it\n",
    "import pickle\n",
    "with open('mnt/data/pkl_best.pkl', 'wb') as file:\n",
    "    pickle.dump(mlp, file)\n",
    "\n",
    "print(\"Model saved as pkl_best.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Explanation and References\n",
    "\n",
    "- **TF-IDF Vectorization**: TF-IDF is a statistical measure used to evaluate how important a word is to a document in a collection or corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus. Reference: Manning, C. D., Raghavan, P., & Schütze, H. (2008). Introduction to Information Retrieval. Cambridge University Press.\n",
    "- **MLPClassifier**: A Multilayer Perceptron (MLP) is a class of feedforward artificial neural network (ANN). An MLP consists of at least three layers of nodes: an input layer, a hidden layer, and an output layer. Except for the input nodes, each node is a neuron that uses a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training. Reference: Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep Learning. MIT Press."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
